\documentclass[12pt,english]{article}

\usepackage{amsmath,amssymb,amsthm,epsfig,lineno,rotfloat,psfrag,natbib,caption,setspace,url,bm,geometry}
\usepackage{ecology}
\usepackage{graphicx}

\geometry{verbose,letterpaper,tmargin=2.54cm,bmargin=2.54cm,lmargin=2.54cm,rmargin=2.54cm}

%\setlength{\evensidemargin}{0in} \setlength{\oddsidemargin}{0in}
%\setlength{\topmargin}{-0.65in} \setlength{\textwidth}{6.5in}
%\setlength{\textheight}{9.5in} \setlength{\topskip}{0in}
%\setlength{\headheight}{0in}


%\newcommand{\yst}{\ensuremath{y_{st}}}
%\newcommand{\tyst}{\ensuremath{\tilde y_{st}}}
%\newcommand{\tzs}{\ensuremath{\tilde z_{s}}}
%\newcommand{\zs}{\ensuremath{z_{s}}}
%\newcommand{\bg}{\ensuremath{\boldsymbol{\gamma}}}
%\newcommand{\bxs}{\ensuremath{\mathbf{x}_{s}}}
%\newcommand{\bxst}{\ensuremath{\mathbf{x}_{st}}}
%\newcommand{\bK}{\ensuremath{\mathbf{K}}}
%\newcommand{\bn}{\ensuremath{\boldsymbol{\eta}}}
%\newcommand{\bb}{\ensuremath{\boldsymbol{\beta}}}
%\newcommand{\ba}{\ensuremath{\boldsymbol{\alpha}}}
%\newcommand{\by}{\ensuremath{\mathbf{y}}}
%\newcommand{\bz}{\ensuremath{\mathbf{z}}}
%\newcommand{\bX}{\ensuremath{\mathbf{X}}}
%\newcommand{\be}{\ensuremath{\boldsymbol{\epsilon}}}
%\newcommand{\bQ}{\ensuremath{\mathbf{Q}}}
%\newcommand{\bO}{\ensuremath{\boldsymbol{\Omega}}}
%\newcommand{\bm}{\ensuremath{\boldsymbol{\mu}}}






\bibliographystyle{ecology}
\raggedbottom


\captionsetup[table]{margin=0pt,font=small,labelfont={sc},justification=justified,labelsep=period}
\captionsetup[figure]{margin=0pt,font=small,labelfont={sc},justification=justified,labelsep=period,name=Fig}



\begin{document}
\begin{spacing}{1.9}

\begin{center}
On extrapolating past the range of observed data when making statistical predictions in ecology
\bigskip\\
\normalsize
{\sc Paul B. Conn$^{1,}$\footnotemark[2] and
Devin S. Johnson$^1$, Peter L. Boveng$^1$ }\smallskip\\
$^1${\em National Marine Mammal Laboratory, NOAA, National Marine Fisheries Service,
Alaska Fisheries Science Center, 7600 Sand Point Way NE, Seattle,
WA 98115 USA }\\ \medskip
\end{center}
\footnotetext[2]{Email: paul.conn@noaa.gov}


\raggedright \setlength{\parindent}{0.3in}
%\renewcommand{\baselinestretch}{1.8}\normalsize
\clubpenalty=0
 \linenumbers


{\em Abstract.\ } We'll do this later



{\em Key words: Abundance, Extrapolation, General additive models, Generalized linear models, Independent Variable Hull, Leverage, Prediction variance, Spatial regression, Species distribution model}

\centerline{\sc Introduction}


In ecology and conservation, a common goal is to make predictions about an unsampled random variable given a limited sample from the target population.  For instance, given a model ($\mathcal{M}$), estimated parameters ($\hat{\boldsymbol{\theta}}$), and a covariate vector ${\bf x}_s$, we often desire to predict a new observation $y_s$ at $s$.  For instance, we might use a generalized linear model \citep{McCullaghNelder1989} or one of its extensions to predict species density or occurrence in a new location, or to predict the future trend of a population.

Early in their training, ecologists and statisticians are warned against extrapolating statistical relationships
past the range of observed data.  This caution is easily interpreted in the context of single-variable linear regression analysis; one should be cautious in using the fitted relationship to make predictions at some new point $y_s$ whenever $x_s < \min({\bf x})$ or $x_s > \max({\bf x})$.  But what about more complicated situations
where there are multiple explanatory variables, or when one uses a spatial regression model to account for the residual spatial autocorrelation that is inevitably present in patchy ecological data \citep{LichsteinEtAl2002}?  How reliable are spatially- or temporally-explicit predictions in sophisticated models for animal abundance and occurrence?

Statisticians have long struggled with the conditions under which fitted regression models are capable of
making robust predictions at new combinations of explanatory variables.  The issue is sometimes considered more of a
philosophical problem than a statistical one, and has even been likened to soothsaying \citep{EhrenbergBound1993}.  To our mind, the reliability of predictions from statistical models is likely a function of several factors, including (i) the intensity of sampling,
(ii) spatial or temporal proximity of the prediction location to locations where there are data, (iii) variability of the ecological process, and (iv) the similarity of explanatory covariates in prediction locations when compared to the ensemble of covariates for observed data locations.

Our aim in this paper is to investigate one possibility for defining extrapolation in the generalized linear model and its extensions, including generalized additive models \citep[GAMs;][]{HastieTibshirani1999,Wood2006} and spatial, temporal, or spatio-temporal regression models (STRMs).  In particular, we exploit some of the same ideas used in multiple linear regression regarding leverage and outliers \citep{Cook1979} to operationally define ``extrapolation" as making predictions that occur outside of a generalized independent variable hull (gIVH) of observed data points. Application of the gIVH and related criterion (e.g. prediction variance) can provide intuition regarding the reliability of predictions in unobserved locations, and can aid in model construction and survey design. We illustrate use of the gIVH on simulated count data, on a species distribution model (SDM) for ribbon seals ({\it Histriophoca fasciata}) in the eastern Bering Sea, and on a population trend model for Steller Sea Lions ({\it Phoca fasciata}).

\section{The generalized independent variable hull (gIVH)}

Extrapolation is often distinguished from interpolation.  In a prediction context, we might define (admittedly quite imprecisely) that extrapolation consists of making predictions that are ``outside the range of observed data" while interpolation consists of making predictions ``inside the range of observed data."  But what exactly do we mean by ``outside the range of observed data"?  Predictions outside the range of observed covariates?  Predictions for locations that are so far from places where data are gathered that we are skeptical that the estimated statistical relationship still holds? To help guide our choice of an operational definition, we turn to early work on outlier detection in simple linear regression analysis.

In the context of outlier detection, Cook (\citeyear{Cook1979}) defined an independent variable hull (IVH) as the smallest convex set containing all design points of a full-rank linear regression model.  Linear regression models are often written in matrix form, i.e.
\begin{linenomath*}
\begin{equation*}
  {\bf Y} = {\bf X} \boldsymbol{\beta} + \boldsymbol{\epsilon},
\end{equation*}
\end{linenomath*}
where ${\bf Y}$ give observed data, ${\bf X}$ is a so-called design matrix that includes explanatory variables \citep[see e.g.][]{Draper1966}, and $\boldsymbol{\epsilon}$ represent normally distributed residuals (here and throughout the paper, bold symbols will be used to denote vectors and matrices).
Under this formulation, the IVH is defined relative to the hat matrix, ${\bf V}_{\rm LR}={\bf X}({\bf X}^\prime{\bf X})^{-1}{\bf X}^\prime$ (where the subscript ``LR" denotes linear regression).  Letting $v$ denote the maximum diagonal element of ${\bf V}_{LR}$, one can examine whether a new design point, ${\bf x}_0$ is within the IVH.  In particular, ${\bf x}_0$ is within the IVH whenever
\begin{linenomath*}
\begin{equation}
  \label{eq:IVH}
  {\bf x}_0^\prime ({\bf X}^\prime{\bf X})^{-1}{\bf x}_0 \le v.
\end{equation}
\end{linenomath*}
Cook (\citeyear{Cook1979}) used this concept to identify influential observations and possible outliers, arguing that design points near the edge of the IVH are deserving of special attention.  Similarly, points outside the IVH should be interpreted with caution.

We simulated two sets of design data to help illustrate application of the IVH (Fig. \ref{fig:IVH}).  In simple linear regression with one predictor variable, predictions on a hypothetical response variable obtained at covariate values below the lowest observed value or above the highest observed value are primarily outside of the IVH.  We suspect this result conforms to most ecologists intuition about what constitutes ``extrapolating past the observed data."  However, fitting a quadratic model exhibits more nuance; if there is a large gap between design points, it is entirely possible that intermediate covariate values will also be outside of the IVH and thus more likely to result in problematic predictions.  Fitting a model with two covariates and both linear and quadratic effects, the shape of the IVH is somewhat more irregular, and even includes a hole in the middle of the surface when interactions are modeled (Fig. \ref{fig:IVH}).  These simple examples highlight the sometimes counterintuitive nature of predictive inference, a problem that can only become worse as models with more dimensions are contemplated (including those with temporal or spatial structure).  Fortunately, the ideas behind the IVH provide a potential way forward.

Cook's (1979) formulation for the IVH is particular to linear regression analysis, which assumes iid Gaussian error. Thus, it is not directly applicable to generalized models, such as those including alternative error distributions (e.g., Poisson, binomial) or spatial random effects.  Further, the hat matrix is not necessarily well defined for models with more general spatial structure. However, since the hat matrix is proportional to prediction variance, Cook (1979) notes that design points with maximum prediction variance will be located on the boundary of the IVH.  We therefore define a generalized independent variable hull (gIVH) as the set of all potential design points $\mathcal{S}_0$ (note that $\mathcal{S}_0$ can include both observed and unobserved design points) such that
\begin{linenomath*}
\begin{equation}
  \label{eq:gIVH}
  {\rm var}(\lambda_s) \le {\rm max} [{\rm var}(\boldsymbol{\lambda}_{\mathcal{S}})],
\end{equation}
\end{linenomath*}
where $s \in \mathcal{S}_0$, $\lambda_s$ corresponds to the mean prediction at $s$, $\mathcal{S}$ denotes the set of observed design points, and $\boldsymbol{\lambda}_\mathcal{S}$ denotes predictions at $\mathcal{S}$.

Generalizations of the linear model are often written in the form
\begin{linenomath*}
\begin{equation}
  Y_s \sim f_Y(g(\mu_s)),
\end{equation}
\end{linenomath*}
where $f_Y$ denotes a probability density or mass function (e.g. Bernoulli, Poisson), $g$ gives an inverse link function, and
$\mu_s$ is a linear predictor.  For many such generalizations, it is possible to specify the $\mu_s$ as
\begin{linenomath*}
\begin{equation}
  \boldsymbol{\mu} = {\bf X}_{aug}\boldsymbol{\beta}_{aug} + \boldsymbol{\epsilon},
  \label{eq:mu-aug}
\end{equation}
\end{linenomath*}
where the $\boldsymbol{\epsilon}$ represent Gaussian error, ${\bf X}_{aug}$ denotes an augmented design matrix, and $\boldsymbol{\beta}_{aug}$ denote an augmented vector of parameters.  For instance, in a spatial model, $\boldsymbol{\beta}_{aug}$ might include both fixed effect parameters and spatial random effects in a reduced dimension subspace (see Appendix A for examples of how numerous types of models can be written in this form).

When models are specified as in Eq. \ref{eq:mu-aug}, we can write prediction variance generically as
\begin{linenomath*}
\begin{equation}
  \label{eq:var-mu}
  {\rm var}(\boldsymbol{\mu}_x)= {\bf x} {\rm var}(\hat{\boldsymbol{\beta}}_{aug}) {\bf x}^\prime,
\end{equation}
\end{linenomath*}
where it is understood that the exact form of ${\bf x}$ and ${\rm var}(\hat{\boldsymbol{\beta}}_{aug})$ depends on the model chosen (i.e., GLM, GAM, or STRM; Appendix A). This expression for prediction variance is on the linear predictor scale; if a non-identity link function is used, we can use the delta method \citep{Dorfman1938,VerHoef2012} to approximate prediction variance on the real scale (i.e. the scale in which data are measured) as
\begin{linenomath*}
\begin{eqnarray}
  \label{eq:var-lambda}
  {\rm var}(\boldsymbol{\lambda}_x) & = & {\rm var}(g(\boldsymbol{\mu}_x)) \\
  & \approx & \boldsymbol{\Delta} {\rm var}(\boldsymbol{\mu}_x)\boldsymbol{\Delta}^\prime,
%  \boldsymbol{\Delta} & = & \left[ \begin{array}{cccc}
%      \frac{\partial g(\mu_1)}{\partial \mu_1} & \frac{\partial g(\mu_1)}{\partial \mu_2} & %\hdots & \frac{\partial g(\mu_1)}{\partial \mu_n} \\
%      \frac{\partial g(\mu_2)}{\partial \mu_1} & \frac{\partial g(\mu_2)}{\partial \mu_2} & %\hdots & \frac{\partial g(\mu_2)}{\partial \mu_n} \\
%      \vdots & \vdots & \ddots & \vdots \\
%      \frac{\partial g(\mu_n)}{\partial \mu_1} & \frac{\partial g(\mu_n)}{\partial \mu_2} & %\hdots & \frac{\partial g(\mu_n)}{\partial \mu_n} \\
%  \end{array} \right].
\end{eqnarray}
\end{linenomath*}
where $\boldsymbol{\Delta}$ is a matrix of partial derivatives $\partial g(\mu_r)/\partial \mu_c$ ($r$ and $c$ denoting rows and columns of $\boldsymbol{\Delta}$, respectively).  Under common univariate link functions (e.g. log, logit, probit), $\boldsymbol{\Delta}$ has a diagonal form, while for multivariate links (e.g. multinomial logit) $\boldsymbol{\Delta}$ will be dense.

Unlike Cook's original formulation, the gIVH will often involve unknown parameters.  Further, the exact form of ${\rm var}(\hat{\boldsymbol{\beta}}_{aug})$ depends on the underlying model structure and estimation procedure.  For most of the following treatment, we shall assume that data have already been collected (see Discussion for comments on the potential use of the gIVH in survey planning), and that informative probability distributions can be specified for these parameters.  Specifically, we impose a probability distribution $[\boldsymbol{\theta}]$ for unknown parameters, and compute prediction variance as
\begin{linenomath*}
\begin{equation}
  \label{eq:E_var_lambda}
  {\rm var}(\boldsymbol{\lambda}_x | {\bf Y}) = \int_{\boldsymbol{\theta}} {\rm var}(\boldsymbol{\lambda}_x | {\bf Y}, \boldsymbol{\theta}) [\boldsymbol{\theta}] d \boldsymbol{\theta}.
\end{equation}
\end{linenomath*}
Our approach in this paper is to conduct a Bayesian analysis and substitute the posterior distribution $[\boldsymbol{\theta}|{\bf Y}]$ for $[\boldsymbol{\theta}]$ in Eq. \ref{eq:E_var_lambda}.  However, one could also consider substituting parametric approximations based on output from standard likelihood-based analyses.

We propose to use the gIVH in much the same manner as Cook (1979).  In particular, we use the gIVH to differentiate whether spatial predictions are interpolations (predictive design points lying inside the gIVH) or extrapolations (predictive design points lying outside the gIVH).  The gIVH, together with posterior prediction variance, seem ideally situated to diagnosing potential extrapolation issues. Further, one can compare prediction variance in places one has data to places where predictions are desired to gauge the relative amount of information that predictions will be based on.

\subsection{Computing}

We developed a package \texttt{SpatPred} in the R statistical programming environment \citep{RTeam2012} to simulate data and conduct all analyses.  The seal and sea lion datasets are included as part of this package, and are available at \url{https://github.com/pconn/SpatPred}.  The R package has also been archived via figshare [WE PLAN TO DO THIS WHEN THE MANUSCRIPT IS ACCEPTED FOR PUBLICATION].


\section{Examples}

We used simulation to investigate the usefulness of the gIVH for limiting the scope of inference when fitting models to count data that have already been collected.  We also applied the gIVH to examining the robustness of a species distribution model (SDM) of ribbon seals in the eastern Bering Sea, and to time series projections of Steller sea lion population trends.

\subsection{Simulation study}


We conducted a simulation study to investigate whether the gIVH (and accompanying prediction variance) was useful in diagnosing prediction biases when analyzing animal count data. For each of 100 simulations, we generated animal abundance over a $30 \times 30$ grid assuming that animal density was homogeneous in each grid cell.  Animal abundance was generated as a function of three hypothetical spatially autocorrelated habitat covariates (Appendix B).   For each simulated landscape, we conducted virtual surveys of $n=45$ survey units using two different designs: (1) a spatially balanced sample using a random tesselation design \citep{StevensOlsen2004}, and (2) a convenience sample where the probability of sampling was greater for cells closer to a ``base of operations" located in the middle of the survey grid. The former approach preserves randomness while seeking a degree or regularity when distributing sampling locations across the landscape, while the latter may be easier to implement.

We configured virtual sampling quadrats such that they encompassed 10\% of the area of each selected grid cell.  For ease of presentation and analysis, we assumed detection probability was 100\% in each quadrat.  Once animal counts were simulated, three different estimation models were fitted to the data: a GLM, a GAM, and an STRM (Appendix A).  The GLM and STRM expressed log-density as a function of linear and quadratic covariate effects (as well as first order interactions), while the GAM used a kernel smoother with 4 knots for each covariate (Appendix A).  Each model was provided with two of the three covariates used to generate the data.

For each simulated data set and model structure, we calculated the posterior predictive variance and resulting $\text{gIVH}$ as in Eq. \ref{eq:gIVH}. We then calculated posterior predictions of animal abundance within and outside of each gIVH in order to gauge bias as a function of this restriction.  Specifically, the performance of $\text{gIVH}$ may help decide its utility in limiting the scope of inference once data have been collected and analyzed, and perhaps point out areas worthy of additional sampling.  A fuller, technical description of the simulation study design is provided in Appendix B; for illustration of a single simulation replicate see Fig. \ref{fig:sim_maps}.

Posterior predictions from simulations indicated that the distribution for proportional error in total abundance was right skewed when statistical inference was made with regard to the entire survey area (Fig. \ref{fig:sim_boxplots}).  This was particularly true for GLM and STRM models, and was exacerbated when convenience sampling was employed.  The magnitude of mean absolute bias was reduced when inference was constrained to the gIVH for all 6 configurations of survey design and estimation model.  Interestingly, the convolution kernel GAMs we employed often underestimated total abundance, perhaps because of dampening ``edge effects" at extreme ranges of observed covariates, or possibly because interactions among covariates were not modeled.  For GLMs and STRMs, positive proportional bias was the rule, and was of concerning magnitude (e.g. $\approx 0.3$; Fig. \ref{fig:sim_boxplots}) for GLMs and STRMs when convenience sampling was employed and inference was not restricted to the gIVH.  


\subsection{Ribbon seal SDM}
As part of an international effort, researchers with the U.S. National Marine Fisheries Service conducted aerial surveys over the eastern Bering Sea in 2012 and 2013.  Agency scientists used infrared video to detect seals that were on ice, and collected simultaneous digital photographs to provide information on species identity. Here, we use spatially referenced count data from photographed ribbon seals, {\it Phoca fasciata} (Fig. \ref{fig:ribbon}) on a subset of 10 flights flown over the Bering Sea from April 20-27, 2012.  We limited flights to a one week period because sea ice melts rapidly in the Bering Sea in the spring, and modeling counts over a longer duration would likely require addressing how sea ice and seal abundance changes over both time and space \citep[see][]{ConnEtAl2015}. However, limiting analysis to a one week period makes the assumption of static sea ice and seal densities tenable \citep{ConnEtAl2014}.

Our objective with this dataset will be to model seal counts on transects through 25km by 25km grid cells as a function of habitat covariates and possible spatial autocorrelation. Estimates of apparent abundance can then be obtained by summing predictions across grid cells. Figure \ref{fig:flights} shows the transects flown and the number of ribbon seals encountered in each cell, and Figure \ref{fig:covs} show explanatory covariates gathered to help predict ribbon seal abundance.  These data are described in fuller detail by \citet{ConnEtAl2014}, who extend the modeling framework of STRMs to account for incomplete detection and species misidentification errors.  Since our focus in this paper is on illustrating spatial modeling concepts, we devote our efforts to the comparably easier problem of estimating apparent abundance (i.e., uncorrected for vagaries of the detection process).

Inspection of ribbon seal data (Fig. \ref{fig:flights}) immediately reveals a potential
issue with spatial prediction: abundance of ribbon seals appears to be maximized in the southern and/or southeast quadrant of the surveyed area.  Predicting abundance in areas further south and east may thus prove problematic, as the values of several explanatory covariates (Fig. \ref{fig:covs}) are also maximized in these regions.  To illustrate, let $Y_i$ denote the ribbon seal count ($Y_i$) obtained in sampled grid cell $i$.  Suppose that counts arise according to a log-Gaussian Cox process, such that
\begin{eqnarray}
  \label{eqn:Cox}
  Y_i \sim {\rm Poisson}(\lambda_i) \mbox{ and } \\
  \log(\lambda_i) = \log(P_i) + \log(A_i) + \theta_i + \epsilon_i, \nonumber
\end{eqnarray}
where $P_i$ gives the proportion of area photographed in grid cell $i$, $A_i$ gives the proportion of suitable habitat in cell $i$ (ribbon seals do not often utilize land), $\theta_i$ is a linear predictor, and $\epsilon_i$ is normally distributed $iid$ error.  By formulating $\theta_i$ differently, we can arrive at representations characteristic of GLMs, GAMs, and STRMs (see Appendix S1).

We start by fitting a hierarchical GLM, GAM, and STRM to the full suite of predictor covariates (Fig. \ref{fig:covs}).  For the GLM and STRM, we fit a model with linear effects of all predictor variables, and with an additional quadratic term for ice concentration \citep[seal density is often maximized at an intermediate value of ice concentration; see][]{VerHoef2013,ConnEtAl2014}. For the STRM, we imposed a restricted spatial regression (RSR) formulation for spatially autocorrelated random effects, where dimension reduction was accomplished by only selecting eigenvectors of the spectral decomposition associated with eigenvalues that were greater than 0.5 (see Appendix S1 for additional information on model structure).  For the GAM, we employed smooth terms with 8 knots for each covariate.  This included 4 knots at the minimum, 1/3 and 2/3 quantiles, and the maximum observed covariate values, in addition to 4 knots above and below the range of observed data to reduce the magnitude of biased endpoint behavior.

As with simulated data examples, we adopted a Bayesian perspective and conducted estimation using MCMC (see Appendix S1 for algorithm details) with 60,000 iterations where the first 10,000 iterations were discarded as a burn-in.  We generated posterior predictions of ribbon seal abundance across the landscape as
\begin{equation}
  N_i \sim {\rm Poisson}(A_i \lambda_i),
\end{equation}
and calculated the gIVH as in Eqn. \ref{eq:gIVH}, with delta method modifications as specified in Eqns. \ref{eq:var-mu}-\ref{eq:E_var_lambda}.
Initial spatial predictions using the three models (GLM, GAM, STRM) all produced extremely high, unbelievable predictions along the southern boundary of the study area \ref{fig:ribbon_plot}.  Predictions in this region were also largely out of the gIVH, indicating the potential utility for the gIVH in revealing problematic extrapolations.

We considered several possible alternatives for trying to obtain more robust abundance estimates before settling on a preferred alternative.  First, one could refine the study area to eliminate predictions outside of the gIVH (as in the simulation study).  However, this is not ideal in that one does not get an abundance estimate for the whole study area, and it may be difficult to compare abundance from one year to the next using this approach. Second, one could consider a simpler estimation model, such as one post-stratifying by ecoregion as was used in a previous analysis of ribbon seal data to try to avoid this problem \citep{ConnEtAl2014}.  Finally, one could build in a priori knowledge of habitat preferences into the model structure.  We adopted the latter solution, incorporating ``pseudo-absences" (i.e., zero counts where sampling was not conducted) in locations where it would have been (nearly) impossible to detect seals.  Specifically, we inserted pseudo-absences in cells where ice concentrations were $<0.1\%$.  This solution seemed the most logical, as many of the large, anomalous predictions were over open water along the southern edge of the study area, where we would have obtained zero counts had they been surveyed.

Fitting our three models to the augmented dataset with pseudo-absences, most predictions occurred within the gIVH (Fig. \ref{fig:ribbon_plot}).  The largest difference among the three models was in the southwest corner of the study area, coinciding with the few cells that were outside the gIVH in the three models.  Posterior summaries of abundance across the study area were very comparable (albeit with a longer right hand tail for the STRM), with $5\%$, $50\%$, and $95\%$ posterior prediction quantiles as follows: GLM (48686,64836,93927); GAM(46120,61214,90873); STRM(41039,63717,194095).  We note that these estimates are for example illustration only, as they are uncorrected for imperfect detection \citep[e.g., incomplete detection of thermal cameras, animals that were unavailable for sampling because they were in the water, species misidentification; see][]{ConnEtAl2014}.



\subsection{Steller sea lion trends}




\section{Discussion}

We have demonstrated the capacity for certain classes of statistical models to produce biased predictions of animal abundance when extrapolating past the range of observed data.  In simulations, commonly used models (GLMs, STRMs) exhibited positive bias when predictions were required for the entire study area, particularly when convenience sampling was employed; in the ribbon seal example, naive extrapolation of fitted statistical relationships produced high positive bias along the southern boundary of the study area; and in the Steller sea lion example, projected abundance trends were increasingly implausible the farther the predictions were from the realm of observed data.  However, the gIVH appeared useful in diagnosing places where extrapolations from the fitted statistical model were problematic.  For instance, in the simulation study, limiting the scope of inference to locations falling within the gIVH reduced or eliminated bias.  For ribbon seal relative abundance, it was useful for confirming that the naive models needed to be reformulated, and that reformulated models (with pseudo-absence data) produced predictions in unsurveyed areas that were largely within the realm of observed data.

Use of the gIVH in seal and sea lion applications to identify extrapolation issues was not particularly profound, as experts could easily use ecological knowledge of these populations to identify biologically implausible predictions and come to the conclusion that models either needed to be reformulated or inference limited to a smaller set of design points.  Likewise, one could argue that the high positive bias in the simulation study could likely have been reduced had an expert meticulously examined diagnostics from each simulation replicate and reconfigured estimation models to better match the range of covariates observed. However, such determinations are likely to be quite subjective, and may prove insufficient when there are large number of regression coefficients and interaction terms.  Even relatively simple regression models may exhibit non-intuitive patterns (e.g. Fig. \ref{fig:IVH}).  Further, relying on expert opinion alone in successive rounds of model formulation and fitting may lead to investigators choosing models based on how much they like the results, which is clearly not ideal scientific practice.

Our intent in writing this paper is to raise awareness of potential problems with extrapolation bias in statistical models, and to provide an additional tool (the gIVH) to help diagnose its presence.  Other approaches for selecting models to reduce overfitting, such as cross validation \citep[e.g.][]{PicardCook1984}, are also useful for this purpose, but may not entirely eliminate the problem (particularly for sparse datasets). In fields such as species distribution modeling and model-based abundance estimation, the goal for analysts is often to build predictive maps of species abundance and/or occurrence using a limited number of sample locations.
In such applications, the ultimate aim of analysts should be to build models that have low bias and maximal precision.  However, traditional approaches to quantifying bias (e.g., goodness-of-fit statistics) only work with observed data points.  When inference is extended to unsampled locations, the gIVH appears to be a useful diagnostic for whether bias for predictions in unsampled locations can be expected.

The analyses in this paper focused on abundance estimation, which is necessarily non-negative.  As such, counts are usually analyzed with a log link function, and there is a much greater potential for positive bias than negative.  However, one could also apply the gIVH when predicting species occurrence from presence/absence data.  In this case, common link functions (e.g. probit or logit) are symmetric, and potential for positive and negative bias in predictive maps seem equally likely.  Future research should be directed to examine conditions under which the gIVH is a useful diagnostic in such applications.

One area that gIVH ideas may also prove useful is in formulating survey designs.  The topic of optimal (or near-optimal) spatial design has received considerable attention in the statistical literature, often in the context of designing environmental monitoring systems \citep{DiggleLophaven2006,XiaEtAl2006,Muller2007}.  Optimal designs can differ depend on whether one wishes to minimize a criterion such as integrated prediction variance, or a summary of the information matrix (i.e. if one wishes to optimize regression parameter performance).  Optimal designs can also be sensitive to the structure of the estimation model that is used, so that tailoring a survey design to a particular model can be somewhat dangerous if there is uncertainty about the ultimate ``best" structure for the model used to relate animal abundance and occurrence to landscape or habitat covariates.  Nevertheless, one could still think about augmenting a spatially balanced sampling design with a number of locations which are known or thought to have high leverage as a function of available covariates.  We are excited about this prospect, and it is a subject of current research.

With regards to ribbon seal abundance, we once again caution that the estimates presented here are for illustration only, as numerous factors that influence the detectability of seals was not included in count models used in this paper \citep[but see][]{ConnEtAl2014}. Our approach here was to examine extrapolation and prediction error using relatively simple models, with the understanding that such effects are also likely to occur in complex models with more realistic observation components.  Indeed, our experience is that the magnitude of extrapolation bias can increase when additional data on imperfect detection or species misclassification are included. 


\bibliography{master_bib}

\clearpage

FIGURE 1. A ribbon seal, {\it Phoca fasciata}; the focus of spatial modeling efforts in this paper.

FIGURE 2. Example IVHs constructed from simulated data.  In panels A and B, the investigator plans to model a hypothetical (unmeasured) response variable using a linear regression model as a function of a single covariate, $x$, obtained at a number of design points (denoted with an ``x").  Using $x$ as a simple linear effect (A), only predictions less than the minimum observed value of $x$ or greater than the maximum value of $x$ are outside the IVH (shaded area), as scaled prediction variance in these areas (solid line) are greater than the maximum scaled prediction variance for observed data (dashed line).  Using both linear and quadratic effects of $x$, some intermediate points are also outside the IVH; predictions at these points should also be viewed with some caution.  Panels C $\&$ D show a more complicated IVH when the investigator wishes to relate an unmeasured response variable to linear and quadratic effects of two covariates, $x$ and $y$, either without interactions (C) or with interactions (D).  Any potential predictions in the shaded area are outside of the IVH.

FIGURE 3.  Depiction of a single simulation scenario.  Panels (A-C) give simulated covariate values, panel D gives true animal abundance, (E) gives estimated abundance from a GLM run on count data from a spatially balanced survey design, and (F) gives abundance from a GLM applied to count data from a convenience survey.  In (E-F), predictions outside the gIVH are represented by black boxes, and sampling locations are represented with an x.  For the convenience sample, the median posterior abundance prediction for the entire survey area is $57\%$ greater than true abundance when inference is made to the whole study area.  When inference is limited to the gIVH, median posterior abundance was just $16\%$ greater than true abundance.

FIGURE 4.  Boxplots summarizing distribution of proportional error in the posterior predictive median of abundance for the simulation study as a function of estimation model (x-axis), survey design (columns) and whether or not inference was restricted to the gIVH (rows).  The lower and upper limits of each box correspond to first and third quartiles, while whiskers extend to the lowest and highest observed bias within 1.5 interquartile range units from the box.  Outliers outside of this range are denoted with points.  Horizontal lines within boxes denote median bias.  The two numbers located below each boxplot indicate mean bias (upper number) and the number of additional outliers for which proportional bias was greater than 2.0 (lower number).

FIGURE 5. Aerial survey tracks over the Bering Sea, April 22-29, 2012 (blue lines) overlayed on a tesselated study area consisting of 25km by 25km grid cells (gray lines).  Dark gray indicates land, while the brown line indicates a 1000m depth contour, and the orange line shows the U.S Exclusive Economic Zone (EEZ) boundary (which was used to construct the easterly edge of the survey area). Colored pixels indicate ribbon seal counts along aerial transects. The average effective area surveyed in each grid cell was approximately $2.6km^2$ ($0.4\%$).  Note that surveys were designed to target multiple seal species, several of which had high densities further north (results not shown).

FIGURE 6. Potential covariates gathered to help explain and predict ribbon seal abundance in the eastern Bering Sea.  Covariates include distance from mainland (\texttt{dist\_mainland}), distance from 1000m depth contour (\texttt{dist\_shelf}), average remotely sensed sea ice concentration while surveys were being conducted (\texttt{ice\_conc}), and distance from the southern sea ice edge (\texttt{dist\_edge}).  All covariates except ice concentration were standardized to have a mean of 1.0 prior to plotting and analysis.

FIGURE 7  Posterior mean predictions of ribbon seal apparent abundance across the eastern Bering sea from models fit to survey data.  Each row gives result for different model types (GLM, GAM, or STRM, respectively); left column plots give results for naive runs without pseudo-absences, while plots in the right column give predictions for runs where psuedo-absence data (i.e., 0 counts in cells with less than $0.1\%$ ice) were included. Cells highlighted in black indicate those where predictions were outside the generalized independent variable hull (gIVH).

\clearpage
\centerline{\sc Figures}



\begin{figure}[!h]
\begin{center}
\includegraphics[width=6in]{ribbon}
\end{center}
\caption{ }
\label{fig:ribbon}
\end{figure}

\begin{figure}[!h]
\begin{center}
\includegraphics[width=6in]{IVH_simple2.pdf}
\end{center}
\caption{ }
\label{fig:IVH}
\end{figure}

\begin{figure}[!h]
\begin{center}
\includegraphics[width=6in]{sim_maps.pdf}
\end{center}
\caption{ }
\label{fig:sim_maps}
\end{figure}

\begin{figure}[!h]
\begin{center}
\includegraphics[width=6in]{bias_generic.pdf}
\end{center}
\caption{ }
\label{fig:sim_boxplots}
\end{figure}

\begin{figure}[!h]
\begin{center}
\includegraphics[width=6in]{BOSS_survey_ribbon.pdf}
\end{center}
\caption{ }
\label{fig:flights}
\end{figure}

\begin{figure}[!h]
\begin{center}
\includegraphics[width=6in]{covariates.pdf}
\end{center}
\caption{ }
\label{fig:covs}
\end{figure}

\begin{figure}[!h]
\begin{center}
\includegraphics[width=6in]{ribbon_maps.pdf}
\end{center}
\caption{ }
\label{fig:ribbon_plot}
\end{figure}



\clearpage

\end{spacing}
\end{document} 